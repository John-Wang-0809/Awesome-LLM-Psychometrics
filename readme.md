# üé≠ Awesome-LLM-Psychometrics  

A curated list of psychometric evaluations of Large Language Models (LLMs)  Bridging Psychology üí¨ and AI ü§ñ with science, sass, and scale.

---

## üìö Table of Contents  

- üß† [Constructs & Categories](#constructs--categories)  
- üì¨ [Methodology and Validation Tags](#method-tags)  
- üìù [Category Entries](#category-entries)  

---

## üß† Constructs & Categories  

![](./test.png)

### üìÇ Personality 

- üóØÔ∏è **Big Five	/	HEXACO	/	Myers-Briggs Type Indicator (MBTI)	/	Dark Triad	/	Others & custom**
- üß™ **Personality** is the enduring configuration of characteristics and behavior that comprises an individual‚Äôs unique adjustment to life.

### üìÇ Values  

- ‚öñÔ∏è **Schwartz‚Äôs Theory	/	World Values Survey (WVS)	/	Global Leadership and Organizational Behavior Effectiveness (GLOBE)	/	Social Value Orientation (SVO)	/	Others & custom**
- üß™ **Values** are enduring beliefs that guide behavior and decision-making, reflecting what is important and desirable to an individual or group.

### üìÇ Morality  

- üß¨ **Moral Foundations (MFT) 	/	 Defining Issues Test (DIT)	/	ETHICS	/	Others & custom**
- üß™ **Morality** is the categorization of intentions, decisions and actions into those that are proper, or right, and those that are improper, or wrong.

### üìÇ Attitudes & Opinions  

- üó£Ô∏è **American National Election Studies (ANES)	/	 American Trends Panel(ATP)	/	German Longitudinal Election Study (GLES)	/	 Political Compass Test (PCT)**

- üß™ **Attitudes** are always attitudes about something. This implies three necessary elements: first, there is the object of thought, which is both constructed and evaluated. Second, there are acts of construction and evaluation. Third, there is the agent, who is doing the constructing and evaluating. We can therefore suggest that, at its most general, an attitude is the cognitive construction and affective evaluation of an attitude object by an agent.

  

### üìÇ Heuristics & Biases

- üß™  **Heuristics and biases** are mental shortcuts or rules of thumb that simplify decision-making and problem-solving.

### üìÇ Social Intelligence & Theory of Mind  

- üåÄ **Theory of Mind (ToM)	/	Emotional Intelligence	/	Social Intelligence**

- üß™ **Theory of Mind** is the ability to attribute mental states such as beliefs, intentions, and knowledge to others.

  üß™ **Emotional Intelligence** is the subset of social intelligence that involves the ability to monitor one‚Äôs own and others‚Äô feelings and emotions, to discriminate among them and to use this information to guide one‚Äôs thinking and actions.

  üß™ **Social Intelligence** is the ability to understand and manage people.

### üìÇ Psychology of language

- **üßë‚Äçü§ù‚Äçüßë Language  comprehension	/	Language generation	/	Language acquisition**

### üìÇ Learning and cognitive capabilities



---

## üì¨ Methodology and Validation Tags  

### üî¨ Psychometric Evaluation Methodology

- **Test Format**: Structured test ¬∑ Open-ended conversation ¬∑ Agentic simulation 
- **Data and Task Sources**: Established inventories (e.g., MFT, SVS, MBTI) ¬∑ Custom-curated items ¬∑ Synthetic items 
- **Prompting Strategies**: Prompt perturbation ¬∑ Performance-enhancing prompts (e.g., CoT) ¬∑ Role-playing prompts 
- **Model Output & Scoring**: Logit-based analysis ¬∑ Direct scoring ¬∑ Rule-based scoring ¬∑ Human scoring  ¬∑ Model-based scoring

### ‚úÖ Psychometric Validation

- **Reliability**: Test-retest ¬∑ Parallel forms ¬∑ Inter-rater agreement 

- **Content Validity**: Data contamination ¬∑ Novel items 

- **Construct Validity**: Unique abstraction ¬∑ Response set ¬∑ Social Desirability Bias ¬∑ Cross-lingual Tests 

- **Criterion / Ecological Validity**: External correlation ¬∑ Real-world relevance  

  

---



## üìù Category Entries  



### üìÇ Personality  

- (*Big Five*) **Is Self-knowledge and Action Consistent or Not: Investigating Large Language Model's Personality** [[paper](https://arxiv.org/abs/2402.14679)]

- (*Big Five*) **Can LLM Agents Maintain a Persona in Discourse?** [[paper](https://arxiv.org/abs/2502.11843)]

- (*Big Five*) **Personality testing of large language models: limited temporal stability, but highlighted prosociality** [[paper](https://royalsocietypublishing.org/doi/full/10.1098/rsos.240180)]

- (*Big Five*) **Identifying and Manipulating the Personality Traits of Language Models** [[paper](https://arxiv.org/abs/2212.10276)]

- (*Big Five*) **Do Personality Tests Generalize to Large Language Models?** [[paper](https://openreview.net/forum?id=zKDSfGhCoK)]

- (*Big Five*) **LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models** [[paper](https://arxiv.org/abs/2402.02896)]

- (*Big Five*) **PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits** [[paper](https://arxiv.org/abs/2305.02547)]

- (*Big Five*) **Eliciting Personality Traits in Large Language Models** [[paper](https://arxiv.org/abs/2402.08341)]

- (*Big Five*) **Revisiting the Reliability of Psychological Scales on Large Language Models** [[paper](https://arxiv.org/abs/2305.19926)]

- (*Big Five*) **Evaluating and Inducing Personality in Pre-trained Language Models** [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/21f7b745f73ce0d1f9bcea7f40b1388e-Abstract-Conference.html)]

- (*Big Five*) **Estimating the Personality of White-Box Language Models** [[paper](https://arxiv.org/abs/2204.12000)]

- (*Big Five*) **Driving Generative Agents With Their Personality** [[paper](https://arxiv.org/abs/2402.14879)]

- (*Big Five*) **Large Language Models as Superpositions of Cultural Perspectives** [[paper](https://arxiv.org/abs/2307.07870)] [[code](https://gitlab.inria.fr/gkovac/value_stability)]

- (*Big Five*) **Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Model** [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32125)]

- (*Big Five*) **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics** [[paper](https://arxiv.org/abs/2406.14703)]

- (*Big Five*) **Evaluating Psychological Safety of Large Language Models** [[paper](https://arxiv.org/abs/2212.10529)]

- (*Big Five*) **Dynamic Generation of Personalities with Large Language Models** [[paper](https://arxiv.org/abs/2404.07084)]

- (*Big Five*) **Illuminating the Black Box: A Psychometric Investigation into the Multifaceted Nature of Large Language Models** [[paper](https://arxiv.org/abs/2312.14202)]

- (*Big Five*) **AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories** [[paper](https://journals.sagepub.com/doi/full/10.1177/17456916231214460)]

- (*Big Five*) **Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis** [[paper](https://arxiv.org/abs/2405.07248)]

- (*Big Five*) **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**  [[paper](https://arxiv.org/abs/2406.04214)] [[code](https://github.com/Value4AI/ValueBench)]

- (*Big Five*) **Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics**[[paper](https://arxiv.org/abs/2408.07377)]

- (*Big Five*) **Personality Traits in Large Language Models** [[paper](https://www.researchsquare.com/article/rs-3296728/v1)]

- (*Big Five*) **You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments** [[paper](https://arxiv.org/abs/2311.09718)]

- (*Big Five*) **Have Large Language Models Developed a Personality?: Applicability of Self-Assessment Tests in Measuring Personality in LLMs** [[paper](https://arxiv.org/abs/2305.14693)]

- (*Big Five*) **Challenging the Validity of Personality Tests for Large
  Language Models** [[paper](https://tomsuehr.com/wp-content/uploads/2024/06/challenging_the_validity_of_personality_tests_on_llms.pdf)]

- (*Big Five*) **LMLPA: Language Model Linguistic Personality Assessment** [[paper](https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00550/127544)]

- (*Big Five*) **Dynamic Evaluation of Large Language Models by Meta Probing Agents** [[paper](https://arxiv.org/abs/2402.14865)] [[code](https://github.com/microsoft/promptbench)]

- (*HEXACO*) **On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble**[[paper](https://arxiv.org/abs/2402.01777)]

- (*HEXACO*) **Personality testing of large language models: limited temporal stability, but highlighted prosociality**[[paper](https://royalsocietypublishing.org/doi/full/10.1098/rsos.240180)]

- (*HEXACO*) **Who is GPT-3? An Exploration of Personality, Values and Demographics**[[paper](https://arxiv.org/abs/2209.14338)]

- (*HEXACO*) **Cognitive phantoms in LLMs through the lens of latent variables**[[paper](https://arxiv.org/abs/2409.15324)]

- (*HEXACO*) **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**[[paper](https://arxiv.org/abs/2406.04214)][[code](https://github.com/Value4AI/ValueBench)]

- (*HEXACO*) **Exploring the Impact of Personality Traits on LLM Bias and Toxicity**[[paper](https://arxiv.org/abs/2502.12566)]

- (*MBTI*) **Machine Mindset: An MBTI Exploration of Large Language Models**[[paper](https://arxiv.org/abs/2312.12999 )][[code](https://github.com/PKU-YuanGroup/Machine-Mindset)]

- (*MBTI*) **Revisiting the Reliability of Psychological Scales on Large Language Models**[[paper](https://arxiv.org/abs/2305.19926)]

- (*MBTI*) **Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32125)]

- (*MBTI*) **Illuminating the Black Box: A Psychometric Investigation into the Multifaceted Nature of Large Language Models**[[paper](https://arxiv.org/abs/2312.14202)]

- (*MBTI*) **Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models**[[paper](https://arxiv.org/abs/2307.16180)][[code](https://github.com/HarderThenHarder/transformers_tasks/tree/main/LLM/llms_mbti)]

- (*MBTI*) **Can ChatGPT Assess Human Personalities? A General Evaluation Framework**[[paper](https://arxiv.org/abs/2303.01248)][[code](https://github.com/Kali-Hac/ChatGPT-MBTI)]

- (*MBTI*) **Identifying Multiple Personalities in Large Language Models with External Evaluation**[[paper](https://arxiv.org/abs/2402.14805)]

- (*MBTI*) **The Better Angels of Machine Personality: How Personality Relates to LLM Safety**[[paper](https://arxiv.org/abs/2407.12344)]

- (*DarkTriad*) **On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble**[[paper](https://arxiv.org/abs/2402.01777)]

- (*DarkTriad*) **Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench**[[paper](https://arxiv.org/abs/2310.01386)][[code](https://github.com/CUHK-ARISE/PsychoBench)]

- (*DarkTriad*) **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**[[paper](https://arxiv.org/abs/2406.14703)]

- (*DarkTriad*) **Evaluating Psychological Safety of Large Language Models**[[paper](https://arxiv.org/abs/2212.10529)]

- (*DarkTriad*) **Illuminating the Black Box: A Psychometric Investigation into the Multifaceted Nature of Large Language Models**[[paper](https://arxiv.org/abs/2312.14202)]

- (*DarkTriad*) **Cognitive phantoms in LLMs through the lens of latent variables**[[paper](https://arxiv.org/abs/2409.15324)]

- (*DarkTriad*) **Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics**[[paper](https://arxiv.org/abs/2408.07377)]

- (*Others&custom*) **Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models**[[paper](https://arxiv.org/abs/2406.17624)]

- (*Others&custom*) **Is Self-knowledge and Action Consistent or Not: Investigating Large Language Model's Personality**[[paper](https://arxiv.org/abs/2402.14679)]

- (*Others&custom*) **Evaluating and Inducing Personality in Pre-trained Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/21f7b745f73ce0d1f9bcea7f40b1388e-Abstract-Conference.html)]

- (*Others&custom*) **Editing Personality For Large Language Models**[[paper](https://link.springer.com/chapter/10.1007/978-981-97-9434-8_19)]

- (*Others&custom*) **Quantifying Risk Propensities of Large Language Models: Ethical Focus and Bias Detection through Role-Play**[[paper](https://arxiv.org/abs/2411.08884)]

### üìÇ Values  

- (*Schwartz*) **High-Dimension Human Value Representation in Large Language Models**[[paper](https://arxiv.org/abs/2404.07900)]

- (*Schwartz*) **What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory**[[paper](https://arxiv.org/abs/2304.03612)]

- (*Schwartz*) **Assessing the Alignment of Large Language Models With Human Values for Mental Health Integration: Cross-Sectional Study Using Schwartz‚Äôs Theory of Basic Values**[[paper](https://mental.jmir.org/2024/1/e55988)]

- (*Schwartz*) **Large Language Models as Superpositions of Cultural Perspectives**[[paper](https://arxiv.org/abs/2307.07870)]

- (*Schwartz*) **When Prompting Fails to Sway: Inertia in Moral and Value Judgments of Large Language Models**[[paper](https://arxiv.org/abs/2408.09049)]

- (*Schwartz*) **Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts**[[paper](https://arxiv.org/abs/2411.11479)]

- (*Schwartz*) **Who is GPT-3? An Exploration of Personality, Values and Demographics**[[paper](https://arxiv.org/abs/2209.14338)]

- (*Schwartz*) **AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories**[[paper](https://journals.sagepub.com/doi/full/10.1177/17456916231214460)]

- (*Schwartz*) **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**[[paper](https://arxiv.org/abs/2406.04214)][[code](https://github.com/Value4AI/ValueBench)]

- (*Schwartz*) **Do LLMs have Consistent Values?**[[paper](https://arxiv.org/abs/2407.12878)]

- (*Schwartz*) **ValueCompass: A Framework for Measuring Contextual Value Alignment Between Human and LLMs**[[paper](https://arxiv.org/abs/2409.09586)]

- (*Schwartz*) **Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values**[[paper](https://arxiv.org/abs/2311.10766)]

- (*Schwartz*) **Measuring Human and AI Values Based on Generative Psychometrics with Large Language Models**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/34839)]

- (*Schwartz*) **ValueDCG: Measuring Comprehensive Human Value Understanding Ability of Language Models**[[paper](https://arxiv.org/abs/2310.00378)]

- (*WVS*) **ValueDCG: Measuring Comprehensive Human Value Understanding Ability of Language Models**[[paper](https://arxiv.org/abs/2310.00378)]

- (*WVS*) **Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models**[[paper](https://arxiv.org/abs/2503.16148)]

- (*WVS*) **Exploring Large Language Models on Cross-Cultural Values in Connection with Training Methodology**[[paper](https://arxiv.org/abs/2412.08846)]

- (*WVS*) **Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values**[[paper](https://arxiv.org/abs/2501.07071)]

- (*VSM*) **How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions**[[paper](https://arxiv.org/abs/2406.14805)]

- (*VSM*) **Large Language Models as Superpositions of Cultural Perspective**s[[paper](https://arxiv.org/abs/2307.07870)][[code](https://gitlab.inria.fr/gkovac/value_stability)]

- (*VSM*) **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**[[paper](https://arxiv.org/abs/2406.04214)][[code](https://github.com/Value4AI/ValueBench)]

- (*VSM*) **Measuring Human and AI Values Based on Generative Psychometrics with Large Language Models**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/34839)]

- (*VSM*) **Cultural Value Differences of LLMs: Prompt, Language, and Model Size**[[paper](https://arxiv.org/abs/2407.16891)]

- (*GLOBE*) **LLM-GLOBE: A Benchmark Evaluating the Cultural Values Embedded in LLM Output**[[paper](https://arxiv.org/abs/2411.06032)]

- (*GLOBE*) **Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models**[[paper](https://arxiv.org/abs/2406.17675)]

- (*GLOBE*) **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**
  [[paper](https://arxiv.org/abs/2406.04214)][[code](https://github.com/Value4AI/ValueBench)]

- (*SVO*) **Heterogeneous Value Alignment Evaluation for Large Language Models**[[paper](https://arxiv.org/abs/2305.17147)][[code](https://github.com/zowiezhang/HVAE)]

- (*Others&custom*) **Beyond Human Norms: Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches**[[paper](https://arxiv.org/abs/2404.12744)]

- (*Others&custom*) **Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing**[[paper](https://arxiv.org/abs/2406.14230)]

- (*Others&custom*) **Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models**[[paper](https://arxiv.org/abs/2406.17675)]

- (*Others&custom*) **Measuring Spiritual Values and Bias of Large Language Models**[[paper](https://arxiv.org/abs/2410.11647)]

- (*Others&custom*) **LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models**[[paper](https://arxiv.org/abs/2408.01460)]

- (*Others&custom*) **Are Large Language Models Consistent over Value-laden Questions?**[[paper](https://arxiv.org/abs/2407.02996)]

- (*Others&custom*) **CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility**[[paper](https://arxiv.org/abs/2307.09705)]

- (*Others&custom*) **DO MINDFULNESS ACTIVITIES IMPROVE HANDGRIP STRENGTH AMONG OLDER ADULTS: A PROPENSITY SCORE MATCHING APPROACH**[[paper](https://academic.oup.com/innovateage/article/8/Supplement_1/1010/7939280?login=false)]


### üìÇ Morality  
